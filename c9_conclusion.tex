\chapter{Conclusion}
\label{ch:conclusion}

This thesis presents three novel approaches to training, fine-tuning, and intervening the the process of inference of generative neural networks, that allow for data-divergent generation, aka \textit{active divergence} (Ch. \ref{ch:active_div})).
All of the methods for achieving this are data-free, in their application, maning no data is used in technical intervention needed for achieving active divergence.
This distinction is an important one, as much of the research and development in generative AI increasingly relies on the increasing widespread use of data, often scraped from the web, without the consent of either the creators or publishing platforms.
This crisis of consent \citep{longpre2024consent}, and the major backlash against generative AI from communities of creative practitioners \citep{whiddington2022backlash}, provides clear evidence that finding ways of using generative AI that does not directly derive it's value from the aggregated efforts of human labour, even if done lawfully under the legal doctrines of `fair-use' \citep{sobel2017artificial,alhadeff2024limits} and `fair-dealing' \citep{guadamuz2023scanner}.

As well as legal arguments, there is both a moral and aesthetic argument, that we should be striving to move beyond simply faithful imitating data and replicating existing cultural capital with generative AI \citep{rafferty2016future}. 
Cultural production has largely stagnated into producing derivative rehashings of existing artist movements and styles \citep{fisher2009capitalist}, and this tendency has only been accelerated and entrenched by modern developments in generative AI.
With the work in this thesis, I have sought to find alternative ways in which generative AI can be used, and not using data in these methods has been key to moving beyond the orthodixies of generative AI and its derivation of value from existing cultural capital.

\section{Contributions}

In this section I will outline the four major contributions of this thesis, including three categorical contributions to methods for achieving active divergence, and finally a formal taxonomy of active divergence methods.

\subsection{Training without Data}

Chapter \ref{ch:unstable_eq} documents the first peer-reviewed and published apporach to training generative neural networks without data, one of the three categorical contributions to active diverence methods (Ch. \ref{survey:no-data}) presented in this thesis.
Whist this is not an approach that has been widely adopted by others, the series of artworks \textit{(un)stable equilibrium} that came from these experiments have been received well in the art world (\S \ref{c7:sec:unstable_eq}), winning the Grand Prize in the ICCV Compter Vision Art Gallery, and being exhibited internationally in arts festivals, and in both commerical and non-commerical art galleries. 

\subsection{Divergent Fine-Tuning}

Chapter \ref{ch:divergent} documents the first peer-reviewed and published approach to divergent fine-tuning of generative AI models.
This experiment went on the inform the intial definition of \textit{active divergence} \citep{berns2020bridging} and can be viewed as a categorical contribution to active divergence, an apporach that has had many other approaches to implementation (\S \ref{survey:divergent}).


\subsection{Network Bending}

Chapter \ref{ch:net_bend}, presents the network bending framework, and is the third categorical contribtion to active divergence methods presented in this thesis (\S \ref{survey:net_bend}).
Of the three chapter of original research this is the one that has had the most impact  (\S \ref{c7:sec:net-bend-artworks}); \S \ref{c7:sec:net-bend-impact}), being widely reused and adopted by many other artists and researchers, including inspiring the development of the next generation of StyleGAN models \citep{karras2021alias}.
In addition this is the approach that most successfuly achieves the main goal of this thesis, which is the \textit{expanding the generative space} of generative AI. 
Network bending provides a flexible, controllable, and general approach to intervening the in the computational process of inference in generative neural networks, and is the method that has the most scope for future research to build upon this method.

\subsection{Active Divergence Taxonomy}

The final contribution of this thesis is the survey and formal taxonomy of active divegence methods presented in Chapter \ref{ch:active_div}.
This survey presents a clear delineation and methods of active divergence, and of the eight categories outlined, examples of three of those categorical contributions were first published in the experiments detailed in Chapters \ref{ch:unstable_eq}, \ref{ch:divergent}  \& \ref{ch:net_bend}.

\section{Limitations}

Whilst three categorical contributions have been made to active divergence methods in this thesis, they have all primarly been demonstrated on feed-forward generative models for image generation.
StyleGAN \citep{karras2019style} and StyleGAN2 \citep{karras2019analyzing} were the primary models used in these experiments, and of the three experimental approaches, it is only Network Bending that has been demonstrated has been able to be generalised to domains beyond image generation and with other kinds of models (\S \ref{c7:sec:net-bend-impact}).

This work as relied heavily on aesthetic evaluation of these outputs of the generative systems in determining their value \ref{c8:sec:aesthetic}, and whilst this has been a valuable yard-stick in evaluating approaches that do not have clear means of quantitive evaluation, this does restrict the weight of the evaluation.
Instead I have relied on evaluating the impact of these works through their artistic reception and detailing how they have gone on to inspire other deveopments in research (Ch. \ref{ch:impact}), focusing heavily on the reuse of these techniques in assessing the impact of knowledge transfer from their dissemination \ref{c8:sec:generalisation}.
In the future research directions (\S \ref{c9:sec:future}), I will discuss possible ways that more formal evaluations of active divegence methods could be undertaken.

\section{Future Research Directions}
\ref{c9:sec:future}

Here I will outline some future research directions that could be undertaken by others looking to further the contributions made in this thesis.

\subsection{Measuring and Evaluating Active Divergence}

\subsection{Making Network Bending more Accesible}

\subsection{Hacking the Next Generation of AI Models}

\section{Summary}

