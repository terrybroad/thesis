\chapter{Introduction}
\label{ch:intro}

\begin{quote}A Machine Learning algorithm walks into a bar.

The bartender asks, ``What'll you have?"

The algorithm says, ``What's everyone else having?" \citep{haase2017bar} \end{quote}

This joke by Chet Haase, typifies what is an almost universal axiom in machine learning practice and research. 
That is, real-world data, a.k.a the ground truth, contains all the information needed for our algorithms to earn from. 
These algorithms should learn to mimic and imitate this data in an unquestioning and uncritical fashion, because real world data, collected, created or labelled by humans, is all they will need to achieve the aims that we determine they should strive for.

This ethos applies to almost all machine learning research and development. In the context of generative machine learning research, a great deal of success has been made by imitating data. 
Realistic synthesis of images (CITE), text (CITE) and audio (CITE) were all made possible using this approach. 
Striving for realism though, can only get you so far, and in many other creative technological contexts, realism is a goal that has been superseded by other aims. 
In video games and VfX, non-photographic rendering is wide-spread, and underpins the success of many of the most famous games and animated feature films (CITE). 
In music, the unique qualities of electronically synthesised audio have spawned many musical genres, and digital audio workstations have fundamentally changed the way that people produce, perform and listen to music.

Achieving realism is not the only goal of generative AI research. 
Lots of researchers use datasets of paintings, or recordings of musical instruments for training their AI systems. 
The art collective Obvious Art, famously sold an AI-generated artwork \textit{Edmond de Belamy} at the Christies auction house for \$432,500 \citep{christies2018edmond}.
This was done by taking a dataset of traditional western paintings, and training a generative neural network on this dataset. 
A new \textit{`painting’} was created by cherry picking an generated output from this generative model, and was then digitally printed onto canvas and adorned in a gilded frame, resurrecting an antiquated practice that dates back to the renaissance and that peaked in 18th and 19th century Europe, where aesthetic and cultural value is prescribed to painted works by placing them in ornate, highly decorated frames.

While training generative AI on paintings is not the same goal as achieving photorealism (though they are imitating, digitised, photographic images of physical works), this type of work still has to goal of imitating the representations of real-world phenomena, just here we are imitating the representations of traditional hand-crafted works, often those that have historical cultural value.

There have been some attempts to make generative AI produce more creative outputs. 
Continuing with the theme of generating paintings, the ‘Creative Adversarial Networks’ algorithm was designed to create ‘original artworks’ with ‘new styles’, by training the AI to deviate from the categories of historical art movements, but to still generate images that look like paintings \cite{elgammal2017can}. 
This research was released to much fanfare and was even featured in an episode of HBO’s Silicon Valley sitcom \citep{elhoseiny2019hbo}. 
The art critic for the New York Times, Jerry Salz, however, was less enthusiastic about the originality of the works generated by this algorithm. 
In a video produced for Vice magazine, he describes one of these CAN generated paintings as being “incredibly dull, generic, boring [...] If the ultimate test is could this have been made by a human, the answer is yes, it has been a thousandth to the thousandth time [...] What I feel is bored when I look at it, what I feel is a lack of originality in the idea that generated it” \citep{saltz2018aiart}. 

\section{The Backlash Against AI Art}

``NO TO AI GENERATED IMAGES", that was the caption on a widely shared meme that was posted to artstation, deviantart and other art platforms where traditional artists would share portfolios of their work as a protest to the proliferation of AI generated artworks using text to image models which had been trained on data harvested from these very platforms. 

\textbf{INSERT FIGURE HERE}

The outrage was levelled at recent developments in text-to-image models from startups such as \cite{midjourney2023midjourney} and \cite{stability2023stability} , that had been trained on large swathes of data collected from internet, including web platforms designed for people to share their art, as a means of having an online portfolio to raise their public profile, and in many cases, marketing their work for people to buy or to attract freelance work, or to gain employment as an artist, graphic designer, or illustrator.

While text to image models had been around for some time, the developments in 2022 with diffusion based models like dalle-2 \citep{openai2022dalle2}, MidJourney v4 \citep{edwards2022midjourney} and stable diffusion \citep{stability2022stable}, and their ability to so successfully imitate the existing styles of individual artists, simply by listing the names of well known creators on these digital platforms in the input text prompt, sparked outrage in the creative communities where a lot of the data was sourced. 
Taking the entire body of individual artists' works for training data without consent and without remuneration, was a large part of the outrage.
There are also legitimate and substantiated fears, that these generative AI systems will put creatives out of work and lower the barrier to entry for image generation so considerably to make it a trivial pursuit requiring little skill or training to produce commercially viable results.


Much of the content shared in protest against AI art was quoted with statements such as “AI is theft” \citep{whiddington2022backlash}, with trending hashtags like \#SupportHumanArtists \citep{zakuga2022theft}. 
Several ongoing lawsuits have emerged against companies like midjourney and stability.ai, from artists themselves [CITE] and from companies like Getty Images and shutterstock that provide stock photographs and artworks [CITE]. 
Many artists have now removed their work portfolios from publicly available sites, and artstation and deviantart now have metadata tags for ‘NoAI’ \citep{artstation2022noai}, meaning permission is withheld for those works to be used in creating datasets for training AI systems, which users on deviantart platforms are opted into by default \citep{deviantart2022optout}. 

My opinion is that the concerns and grievances of these artists are completely legitimate. 
I've been an active member in the CreativeAI community since it’s inception, and to see big tech startups entering this space and behave with such contempt for the communities of artists for which much of their value and power is sourced is very disheartening to see. 
The work in this thesis is positioned in opposition and as an alternative to the practices of these large tech organisations. 
\textbf{Can we end with a question for the reader here?}

\section{Intellectual Property and AI Art}

My first encounters with the issues of copyright, ownership and authorship of work with generative AI predate these developments. 
In 2015-16 I was working towards a research Masters thesis in Creative Computing at Goldsmiths just as generative AI research was starting to take off. 
In one of the experiments outlined in the thesis, I used all the frames from the film Blade Runner as the training data for an autoencoder model, which after training I used to make a reconstruction of the film through the learned model \citep{broad2016autoencoding}.
The film \textit{Blade Runner -- Autoencoded} garnered a large international interest and I was very lucky to have had the work exhibited around the world in major museums and galleries \citep{broad2017autoencoding}.

The training data, of course, was not intellectual property that I had the rights or ownership of. 
Ironically, because of that and the resulting (and later rescinded) DMCA copyright takedown notice given to the videos on the web platform Vimeo, was what catapulted the work to international recognition after an account of these travails was detailed in the news website Vox \citep{romano2016bladerunner}.

Though I did not face any legal ramifications from Warner Brothers for doing the work, an opinion published in the Columbia Journal of Law and the Arts predicted that the work would probably be dealt with as copyright infringement were it tested in an American court \citep{sobel2017artificial}. 
I produced that work before the widespread emergence of NFTs and before there was ever a large market for AI generated artworks. 
The money I made from exhibition fees and selling editions of the video work would have been small fry for a large multinational media company. 
Nonetheless, finding ways of using generatie AI that do not rely on data, and other people's intellectual property was a key goal for the work in this thesis.

\section{Motivation}

My goal was to find ways of training or configuring generative AI models where I wasn’t relying on making my own datasets to produce creative outcomes. 
From working in industry, I had experience of how labour intensive and all-consuming creating high quality datasets could be, and it was clear this could become a massive time sink in the research process. 
The second was to find ways of achieving novel outcomes that didn’t rely on having access to the high end resources available to the likes of Google DeepMind, NVIDIA, or artists like Refik Anadol who have access to huge computational resources \citep{caulfield2022refik}. 
To this end, I have found ways of training and configuring very high fidelity models that, when trained traditionally, need to be trained on supercomputers. 
This thesis presents a number of ways of manipulating and training the very same models in much shorter time periods on consumer level hardware. 

Instead of relying on laboriously or ethically questionable datasets to try and achieve creative outcomes, the work in this thesis details data-free methods that push the possibility space of what can be generated with these neural networks. 
The approaches detailed are an attempt to use the intrinsic affordances of these neural networks to create truly original outputs, that would not have been possible using any other technique or technology. 
The work detailed in this thesis is experimental image making in its truest sense, and I have taken more inspiration from experimental photographers and filmmakers from the 20th Century than I have from academic researchers.

The driving force that led to each technical breakthrough in this thesis was a technical curiosity. 
When thinking about a new possible configuration for training an AI, or some other kind of intervention, if I couldn’t imagine what the result of that experiment would look like, then I would have to build it to find out, regardless of how many weeks or months of work it would take to get there. 
The results presented here are the experiments that produced the most surprising and striking results. 
Sometimes beautiful and sometimes horrifying. 
There were a lot of failed experiments along the way that produced boring, predictable and uninspiring results. 
I’ve spared the reader details of most of these, apart from the few that led to key insights.

\section{Research Methods}


The breakthroughs in research in this thesis have all come from technological exploration of what is possible with these new technologies. Much of this research has been conducted in the vein of hacking, in its original meaning from the hacker culture at MIT in the 60s and 70s, where hacking meant “exploring the limits of what is possible, in a spirit of playful cleverness” \citep{stallman2002hacking}. 
This hacking ethos is not an approach that many people were taking in machine learning research when I started this PhD. 
The field was, and still is, very much dominated by orthodoxies and ideology, where theoretical mathematical underpinnings, achieving state of the art performance on some widely used benchmark, and generalisation are most valued by the research communities \citep{birhane2022values}.

\textit{Hacking} was the primary means by which the algorithms in this thesis were discovered, but artistic exploration has also been central to the experimental work described in this thesis. 
When I started this PhD, my plan was to do primarily technical research, and continue with an artistic practice on the side, maybe using some of the techniques developed in my research. 
But instead, it was artistic enquiry that led me to the technical breakthroughs in the PhD, not the other way round. 

In his paper \textit{"Art in the sciences of the artificial"} Stanley argues that in the fields of artificial intelligence research and artificial life. 
Subjective evaluation is a key driving force of progress for many researchers and practitioners in the field. 
There is a tendency in these research fields to discourage the dissemination of these observations in academic writing and wider public discourse. 
Something that Stanley worries might “cut off some future discoverers from what could have been their inspirations” \citep{stanley2018art}. 
In this writeup I have not shied from sharing my subjective position at various times in the thesis, and how that informed the direction of following research experiments.

Being both guided by, and disseminating this kind of subjectivity is commonplace in research in the humanities (CITE), but is often an anathema in traditional computer science research, where ‘neutral’ objectivity is venerated (CITE). 
While striving for objectivity has led to many accomplishments in scientific research, it also has significant issues and has led to perverse incentives in many areas of science (CITE). 

The goal of this research has been at its core, to advance the creative possibilities of these technologies. 
As a practising and internationally recognised visual artist, my subjective understanding of the visual and aesthetic of these systems, has been one of the central guiding instruments in this research. 
To give any other account of how this research was conducted would be a failing of academic integrity. 

\section{Summary and Overview}

The thesis is titled \textit{Expanding the Generative Space}. 
The through line of all of the research presented here has been to find ways of going beyond the imitation of training data as the sole way of training generative neural networks. 
Instead, I have been trying to expand the possibility space that generative AI can produce, and the methods described in this thesis are but a few of the ways that this is possible. 

The next chapter gives a background of work prior to the PhD. 
Both in the technical aspects of machine learning, but also its application in a creative context, and the broader history of artificial intelligence methods such as evolutionary algorithms, and their applications for generative processes. 
This chapter also details the prior work in attempts to achieve novel outcomes with generative neural networks.

Chapters 3, 4 and 5 details the experiments for three different techniques for actively diverging from data. 
All three of these chapters present distinct categorical contributions to the field of generative AI. 
None of these techniques rely on data for the training, fine-tuning or run-time manipulation of the generative systems. 
Chapter 6 goes on to detail the impact of the experimental work and the subsequent research and development by others that this research went on to inspire. 

All of the experimental work in this thesis for deliberately diverging from data with generative neural networks, instead of imitating it, falls under the umbrella term active divergence. 
This was first coined by a PhD colleague and friend of mine Sebastian Berns and his supervisor Simon Colton [\citeyear{berns2020bridging}]. 
The core experimental work in this thesis pre-dates this definition, and I am indebted to Sebastian for summarising the overarching theme of my research, which felt far more disparate at the time I was working on it, until he was able to summarise it in a two-word definition. 
In collaboration with Sebastian and Simon, I expanded on this definition and presented a survey and taxonomy of active divergence methods at the International Conference of Computational Creativity in 2021 \citep{broad2021active}.
An updated summary of that survey is presented in Chapter 7 and details a lot of the work done concurrently by others during the time of this PhD to achieve the same goal.

The final chapter concludes the thesis and reflects on the work done, and the significant changes to the field of generative machine learning in the past 6 years, including the societal impacts that has had. 
This chapter goes on to point to avenues for future research in response to these developments, and show a way forward for future research in active divergence, highlighting its importance in the rapidly changing cultural and technical media ecology.  


