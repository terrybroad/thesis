# PhD Thesis

This repo is the latex document of my PhD thesis `*Expanding the Generative Space*: Data-Free Techniques for Active Divergence with Generative Neural Networks' that was completed in 2024 at Goldsmiths, University of London, under the supervision of Professor Mick Grierson and Professor Frederic Fol Leymarie.

You can download the final version of the thesis here: https://drive.google.com/file/d/190uyX_JAJI8IhoGJyshc4t0wwWWU9Eau/view?usp=drive_link

## Abstract 


Generative neural networks offer powerful tools for the generation of data in many domains, given their ability to model distributions of data and generate high-fidelity results. However, a major shortcoming is that they are unable to explicitly diverge from the training data in creative ways and are limited to fitting the target data distribution. This thesis presents a body of work investigating ways of training, fine-tuning, and configuring generative neural networks in inference in order to achieve data-divergent generation. This goal of configuring generative neural networks to diverge from their original training data or any existing data distribution is referred to as *active divergence*. All of the approaches presented in this thesis are data-free in their implementation, which inherently distinguishes these approaches from the traditional orthodoxy of imitation-based learning that is widespread throughout most machine learning research. The research presented in this thesis represents three categorical contributions to achieving active divergence: training without data, divergent fine-tuning, and network bending. In addition to this, a formal survey and taxonomy of active divergence methods is presented as another contribution of this thesis. The overriding goal of the research in this thesis is to *expand the generative space* of generative neural networks. All three methods presented achieve this, and point to a new approach to working with generative neural networks that does not rely on the imitation of, and derivation from data, for extracting its value and creative possibilities.


## Citation

```
@phdthesis{broad2024expanding,
  author = {Terence Broad},
  title = {Expanding the Generative Space: Data-Free Techniques for Active Divergence with Generative Neural Networks},
  year = {2024},
  school={Goldsmiths, University of London}
}
```
